{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import socket and json\n",
    "import socket\n",
    "from time import sleep\n",
    "import pickle\n",
    "\n",
    "# Import required modules\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetAllTextFromContentBody(contentBody):\n",
    "    out_str = ''\n",
    "    for x in contentBody:\n",
    "        out_str += x.text\n",
    "        \n",
    "    return out_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetDateOfArticle(publishedData):\n",
    "    time_, GMT = publishedData.split('+')\n",
    "    dt = datetime.datetime.strptime(time_, '%Y-%m-%dT%H:%M:%S').strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetDateTimeOfArticle(soup):\n",
    "    metatags = soup.find_all('meta',attrs={'name':'publish-date'})\n",
    "    for tag in metatags:\n",
    "        return GetDateOfArticle(tag['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetSentimentalScore(text):\n",
    "    seperator = '#'\n",
    "    analysis = TextBlob(text)\n",
    "    sentiment_value, confidence = analysis.sentiment\n",
    "    print confidence\n",
    "    if confidence*100 >= 70:                 \n",
    "                if sentiment_value > 0.0 :\n",
    "                    return (str(sentiment_value).encode('utf-8') +str(seperator).encode('utf-8') +str('positive').encode('utf-8') )\n",
    "                    \n",
    "                if sentiment_value < 0.0 :\n",
    "                    return (str(sentiment_value).encode('utf-8') +str(seperator).encode('utf-8') +str('negetive').encode('utf-8') )\n",
    "                    \n",
    "                if sentiment_value == 0.0 :\n",
    "                    return (str(sentiment_value).encode('utf-8') +str(seperator).encode('utf-8') +str('neutral').encode('utf-8') )\n",
    "                    \n",
    "    if confidence*100 < 70:\n",
    "                    return (str(sentiment_value).encode('utf-8') +str(seperator).encode('utf-8') +str('invalid').encode('utf-8') )\n",
    "                \n",
    "\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetDataFromLinks(column):\n",
    "        r = requests.get(x)\n",
    "        html_content = r.text\n",
    "        soup = BeautifulSoup(html_content , 'lxml')\n",
    "        contentbody = soup.find_all(\"div\", id=lambda value: value and value.startswith(\"content-body\"))\n",
    "        articleText = GetAllTextFromContentBody(contentbody)\n",
    "        \n",
    "        sentimentValue = GetSentimentalScore(articleText)\n",
    "        articleDate = GetDateTimeOfArticle(soup)\n",
    "        \n",
    "        seperator = '#'\n",
    "                \n",
    "        #arr = ([str(articleDate.encode(\"utf-8\"))],[str(articleText.encode(\"utf-8\"))])\n",
    "        #data_string = pickle.dumps(arr)\n",
    "                    \n",
    "        data_string =  str(articleDate).encode('utf-8')+ str(seperator).encode('utf-8') + str(sentimentValue).encode('utf-8') +'\\n'\n",
    "\n",
    "        return data_string    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "host = \"172.31.20.58\"\n",
    "port = 4212\n",
    "s.bind((host,port))\n",
    "s.listen(10)\n",
    "        \n",
    "        \n",
    "while True:\n",
    "    print('\\nListening for a client at',host , port)\n",
    "    conn, addr = s.accept()\n",
    "    print('\\nConnected by', addr)\n",
    "    try:     \n",
    "            \n",
    "        df = pd.read_csv('all_links.csv')\n",
    "        columnData = df['links']\n",
    "        print (columnData.count)\n",
    "        for x in columnData:            \n",
    "            dataFromLink = GetDataFromLinks(x)\n",
    "            print dataFromLink\n",
    "            conn.send(dataFromLink)\n",
    "            sleep(10)\n",
    "        \n",
    "       \n",
    "    except socket.error:\n",
    "        print ('Error Occured.\\n\\nClient disconnected.\\n')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
